{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import ConvNet\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split twenty test images for visualization\n",
    "def train_test_split(actual_img, output_img, labels):\n",
    "    temp = [0] * 10\n",
    "    test_size = 20\n",
    "    twenty_sample = []\n",
    "    for i in range(len(actual_img)):\n",
    "        if test_size != 0:\n",
    "            if temp[labels[i]] < 2:\n",
    "                temp[labels[i]] += 1\n",
    "                twenty_sample.append([actual_img[i], output_img[i], labels[i]])\n",
    "                test_size -= 1\n",
    "    return twenty_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(visualize_data):\n",
    "    #Visualizing test images in four batches\n",
    "    batch_split = [0,5,10,15,20]\n",
    "    set = 1\n",
    "    for b in range(0,len(batch_split)-1):\n",
    "        fig, axes = plt.subplots(5, 2)\n",
    "        i = 0\n",
    "        for v in visualize_data[batch_split[b]:batch_split[b+1]]:\n",
    "            axes[i, 0].matshow(v[0].reshape(28, 28), cmap='gray')\n",
    "            axes[i, 0].axis('off')\n",
    "            axes[i, 1].matshow(v[1].reshape(28, 28), cmap='gray')\n",
    "            axes[i, 1].axis('off')\n",
    "            i += 1\n",
    "        fig.savefig(\"Image_set{}.png\".format(set), format=\"PNG\")\n",
    "        set +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch, batch_size):\n",
    "    '''\n",
    "    Trains the model for an epoch and optimizes it.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    train_loader: dataloader for training samples.\n",
    "    optimizer: optimizer to use for model parameter updates.\n",
    "    criterion: used to compute loss for prediction and target\n",
    "    epoch: Current epoch to train for.\n",
    "    batch_size: Batch size to be used.\n",
    "    '''\n",
    "\n",
    "    # Set model to train mode before each epoch\n",
    "    model.train()\n",
    "\n",
    "    # Empty list to store losses\n",
    "    losses = []\n",
    "\n",
    "    # Iterate over entire training samples (1 epoch)\n",
    "    for batch_idx, batch_sample in enumerate(train_loader):\n",
    "        data, target = batch_sample\n",
    "\n",
    "        # Push data/label to correct device\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Reset optimizer gradients. Avoids grad accumulation (accumulation used in RNN).\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Do forward pass for current set of data\n",
    "        output = model(data)\n",
    "        if FLAGS.mode == 1:\n",
    "            data = data.view(-1, 784)\n",
    "        # ======================================================================\n",
    "        # Compute loss based on criterion\n",
    "        loss = criterion(output, data)\n",
    "\n",
    "        # Computes gradient based on final loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Store loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Optimize model parameters based on learning rate and gradient\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = float(np.mean(losses))\n",
    "    print('Epoch:{}/{} - Loss: {:.5f}'.format(epoch, FLAGS.num_epochs, epoch_loss))\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, epoch):\n",
    "    '''\n",
    "    Tests the model.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    test_loader: dataloader for test samples.\n",
    "    '''\n",
    "\n",
    "    # Set model to eval mode to notify all layers.\n",
    "    model.eval()\n",
    "    actual_imgs = []\n",
    "    output_imgs = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_sample in enumerate(test_loader):\n",
    "            data, target = batch_sample\n",
    "            actual_imgs.append(data)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if FLAGS.mode==1:\n",
    "                data = data.view(-1, 784)\n",
    "\n",
    "            # Predict for data by doing forward pass\n",
    "            output = model(data)\n",
    "            # ======================================================================\n",
    "            # Compute loss based on same criterion as training\n",
    "            # ----------------- YOUR CODE HERE ----------------------\n",
    "            #\n",
    "\n",
    "            # Remove NotImplementedError and assign correct loss function.\n",
    "            # Compute loss based on same criterion as training\n",
    "\n",
    "            loss = criterion(output, data)\n",
    "\n",
    "            # Append loss to overall test loss\n",
    "            losses.append(loss.item())\n",
    "            output_imgs.append(output)\n",
    "            labels.append(target)\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    return avg_loss, actual_imgs, output_imgs, labels\n",
    "\n",
    "# Function to split twenty test images for visualization\n",
    "def train_test_split(actual_img, output_img, labels):\n",
    "    temp = [0] * 10\n",
    "    test_size = 20\n",
    "    twenty_sample = []\n",
    "    for i in range(len(actual_img)):\n",
    "        if test_size != 0:\n",
    "            if temp[labels[i]] < 2:\n",
    "                temp[labels[i]] += 1\n",
    "                twenty_sample.append([actual_img[i], output_img[i], labels[i]])\n",
    "                test_size -= 1\n",
    "    return twenty_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_main(FLAGS):\n",
    "    # Check if cuda is available\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    filename = open(FLAGS.log_dir, 'w')\n",
    "    sys.stdout = filename\n",
    "    # Set proper device based on cuda availability\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print(\"Torch device selected: \", device)\n",
    "\n",
    "    # Initialize the model and send to device\n",
    "    model = ConvNet(FLAGS.mode).to(device)\n",
    "\n",
    "    # ======================================================================\n",
    "    # Define loss function.\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # ======================================================================\n",
    "    # Define optimizer function.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=FLAGS.learning_rate)\n",
    "\n",
    "    # Create transformations to apply to each data sample\n",
    "    # Can specify variations such as image flip, color flip, random crop, ...\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    # Load datasets for training and testing\n",
    "    # Inbuilt datasets available in torchvision (check documentation online)\n",
    "    dataset1 = datasets.MNIST('./data/', train=True, download=True,\n",
    "                              transform=transform)\n",
    "    dataset2 = datasets.MNIST('./data/', train=False,\n",
    "                              transform=transform)\n",
    "    train_loader = DataLoader(dataset1, batch_size=FLAGS.batch_size,\n",
    "                              shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(dataset2, batch_size=1,\n",
    "                             shuffle=False, num_workers=4)\n",
    "    # print('Number of trainable parameters =', count_parameters(model))\n",
    "    epochs = []\n",
    "    train_losses = []\n",
    "    # Run training for n_epochs specified in config\n",
    "    print(\"--------------------------Training the autoencoder--------------------------\")\n",
    "    for epoch in range(1, FLAGS.num_epochs + 1):\n",
    "        train_loss = train(model, device, train_loader,\n",
    "                           optimizer, criterion, epoch, FLAGS.batch_size)\n",
    "        epochs.append(epoch)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "    print(\"--------------------------Training finished--------------------------\")\n",
    "    print('--------------------------Model Evaluation--------------------------')\n",
    "    avg_test_loss, imgs, recons, labels = test(model, device, test_loader, criterion, epoch)\n",
    "    print('Average test loss: {:.5f}'.format(avg_test_loss))\n",
    "    print('--------------------------Visualizing from test samples--------------------------')\n",
    "    visualize_20 = train_test_split(imgs, recons, labels)\n",
    "    # To display test samples of size 20\n",
    "    visualize(visualize_20)\n",
    "    print('*****************************Check directory for visualization********************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Auto Encoder. [-h] [--mode MODE] [--learning_rate LEARNING_RATE]\n",
      "                     [--num_epochs NUM_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                     [--log_dir LOG_DIR]\n",
      "Auto Encoder.: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"13bf5671-4ac7-4e8c-bc73-d03b12b16118\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=c:\\Users\\bsury\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-9980UiAo2M8UpKw3.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set parameters for Autoencoder\n",
    "    parser = argparse.ArgumentParser('Auto Encoder.')\n",
    "    parser.add_argument('--mode',\n",
    "                        type=int, default=1,\n",
    "                        help='Select mode between 1-2.')\n",
    "    parser.add_argument('--learning_rate',\n",
    "                        type=float, default=0.001,\n",
    "                        help='Initial learning rate.')\n",
    "    parser.add_argument('--num_epochs',\n",
    "                        type=int,\n",
    "                        default=10,\n",
    "                        help='Number of epochs to run trainer.')\n",
    "    parser.add_argument('--batch_size',\n",
    "                        type=int, default=64,\n",
    "                        help='Batch size. Must divide evenly into the dataset sizes.')\n",
    "    parser.add_argument('--log_dir',\n",
    "                        type=str,\n",
    "                        default='logs',\n",
    "                        help='Directory to put logging.')\n",
    "\n",
    "    FLAGS = None\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    parser.parse_args() \n",
    "    run_main(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26ad12ffb58a874a8a329fda28141c0e2e6f327e3911052312e782303b9c94dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
